{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "1ZC-x8KKPODH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcvfuPxLQDaM"
   },
   "source": [
    "# Step 1. ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°\n",
    "- í•œêµ­ì–´ ì±—ë´‡ ë°ì´í„°ëŠ” ì†¡ì˜ìˆ™ë‹˜ì´ ê³µê°œí•œ ì±—ë´‡ ë°ì´í„° : [songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)\n",
    "    1. ì±—ë´‡ íŠ¸ë ˆì´ë‹ìš© ë¬¸ë‹µ í˜ì–´ 11,876ê°œ\n",
    "    2. ì¼ìƒë‹¤ë°˜ì‚¬ 0, ì´ë³„(ë¶€ì •) 1, ì‚¬ë‘(ê¸ì •) 2ë¡œ ë ˆì´ë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7ExFGNDiQF4g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.</td>\n",
       "      <td>ì„¤ë œê² ì–´ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?</td>\n",
       "      <td>ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´</td>\n",
       "      <td>ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12ì‹œ ë•¡!                í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1                  1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´                 ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2                 3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3              3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4                      PPL ì‹¬í•˜ë„¤                ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0\n",
       "...                        ...                       ...    ...\n",
       "11818           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.        í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !      2\n",
       "11819           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.             í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.      2\n",
       "11820              í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.                    ì„¤ë œê² ì–´ìš”.      2\n",
       "11821  í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?  ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.      2\n",
       "11822               í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´        ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = os.getenv('HOME')+'/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "clNy3qdzVLwy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©í•  ìƒ˜í”Œì˜ ìµœëŒ€ ê°œìˆ˜\n",
    "MAX_SAMPLES = len(data)\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "jDjwpD3-VLuq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         12ì‹œ ë•¡!\n",
       "1                    1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´\n",
       "2                   3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤\n",
       "3                3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤\n",
       "4                        PPL ì‹¬í•˜ë„¤\n",
       "                  ...           \n",
       "11818             í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.\n",
       "11819             í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.\n",
       "11820                í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.\n",
       "11821    í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?\n",
       "11822                 í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´\n",
       "Name: Q, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "l8PqYZ1qVLsH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.\n",
       "1                       ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.\n",
       "2                     ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "3                     ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "4                      ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .\n",
       "                   ...           \n",
       "11818          í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !\n",
       "11819               í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.\n",
       "11820                      ì„¤ë œê² ì–´ìš”.\n",
       "11821    ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.\n",
       "11822          ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.\n",
       "Name: A, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k4x4xr0PwmI"
   },
   "source": [
    "# Step 2. ë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸°\n",
    "- ì˜ì–´ ë°ì´í„°ì™€ëŠ” ì „í˜€ ë‹¤ë¥¸ ë°ì´í„°ì¸ ë§Œí¼ ì˜ì–´ ë°ì´í„°ì— ì‚¬ìš©í–ˆë˜ ì „ì²˜ë¦¬ì™€ ì¼ë¶€ ë™ì¼í•œ ì „ì²˜ë¦¬ë„ í•„ìš”í•˜ê² ì§€ë§Œ ì „ì²´ì ìœ¼ë¡œëŠ” ë‹¤ë¥¸ ì „ì²˜ë¦¬ë¥´ ìˆ˜í–‰í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKcjoeLmYN6I"
   },
   "source": [
    "- ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë‘ì (punctuation)ì„ ì œê±°í•˜ì—¬ ë‹¨ì–´ë¥¼ í† í¬ë‚˜ì´ì§•(tokenizing)í•˜ëŠ” ì¼ì— ë°©í•´ê°€ ë˜ì§€ ì•Šë„ë¡ ì •ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "M9CjKWh4Pdj7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def preprocess_sentence(sentence):\n",
    "  # ì…ë ¥ë°›ì€ sentenceë¥¼ ì†Œë¬¸ìë¡œ ë³€ê²½í•˜ê³  ì–‘ìª½ ê³µë°±ì„ ì œê±°\n",
    "  sentence = sentence.lower()\n",
    "\n",
    "  # ë‹¨ì–´ì™€ êµ¬ë‘ì (punctuation) ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "  # ì˜ˆë¥¼ ë“¤ì–´ì„œ \"I am a student.\" => \"I am a student .\"ì™€ ê°™ì´\n",
    "  # studentì™€ ì˜¨ì  ì‚¬ì´ì— ê±°ë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ ê³µë°±ì¸ ' 'ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n",
    "  sentence = re.sub(r\"[^ê°€-í£?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "KWbNIfC8bHeV"
   },
   "outputs": [],
   "source": [
    "def load_conversations():\n",
    "    questions, answers = [], []\n",
    "    for i in range(MAX_SAMPLES):\n",
    "        questions.append(preprocess_sentence(data['Q'].values[i]))\n",
    "        answers.append(preprocess_sentence(data['A'].values[i]))\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "8Jx9gOZ4cd2w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜ : 11823\n",
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜ : 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations()\n",
    "print('ì „ì²´ ìƒ˜í”Œ ìˆ˜ :', len(questions))\n",
    "print('ì „ì²´ ìƒ˜í”Œ ìˆ˜ :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "jwq7iWHXdWHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: ê°€ìŠ¤ë¹„ ì¥ë‚œ ì•„ë‹˜\n",
      "ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: ë‹¤ìŒ ë‹¬ì—ëŠ” ë” ì ˆì•½í•´ë´ìš” .\n"
     ]
    }
   ],
   "source": [
    "print('ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ì§ˆë¬¸ ìƒ˜í”Œ: {}'.format(questions[21]))\n",
    "print('ì „ì²˜ë¦¬ í›„ì˜ 22ë²ˆì§¸ ë‹µë³€ ìƒ˜í”Œ: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opf2E7nXQPMV"
   },
   "source": [
    "# Step 3. SubwordTextEncoder ì‚¬ìš©í•˜ê¸°\n",
    "- í•œêµ­ì–´ ë°ì´í„°ëŠ” í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í¬ë‚˜ì´ì§•ì„ í•´ì•¼ í•œë‹¤ê³  ë§ì€ ë¶„ì´ ì•Œê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ ì•„ë‹Œ ìœ„ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í–ˆë˜ ë‚´ë¶€ ë‹¨ì–´ í† í¬ë‚˜ì´ì €ì¸ SubwordTextEncoderë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë³´ì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmXGeNORewqZ"
   },
   "source": [
    "1. Tensorflow datasets SubwordTextEncoderë¥¼ í† í¬ë‚˜ì´ì € í•œë‹¤. ë‹¨ì–´ë³´ë‹¤ ë” ì‘ì€ ë‹¨ìœ„ì¸ Subwordë¥¼ ê¸°ì¤€ìœ¼ë¡œ í† í¬ë‚˜ì´ì§•í•˜ê³ , ê° í† í°ì„ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ì¸ì½”ë”©í•œë‹¤.\n",
    "2. ê° ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ê° ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ëì„ ë‚˜íƒ€ë‚´ëŠ” START_TOKEN ë° END_TOKENì„ ì¶”ê°€í•œë‹¤.\n",
    "3. ìµœëŒ€ ê¸¸ì´ MAX_LENGHTì¸ 40ì„ ë„˜ëŠ” ë¬¸ì¥ë“¤ì€ í•„í„°ë§í•œë‹¤.\n",
    "4. MAX_LENGTHë³´ë‹¤ ê¸¸ì´ê°€ ì§§ì€ ë¬¸ì¥ë“¤ì€ 40ì— ë§ë„ë¡ íŒ¨ë”©í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlhbFtzRfJ91"
   },
   "source": [
    "### 1. ë‹¨ì–´ì¥(Vocablulary) ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "UpUh_saOQPdU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚´ì§ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”. ìŠ¤íŠ¸ë ˆì¹­ í•œ ë²ˆ í•´ë³¼ê¹Œìš”? ğŸ‘\n",
      "ìŠ=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"ì‚´ì§ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”. ìŠ¤íŠ¸ë ˆì¹­ í•œ ë²ˆ í•´ë³¼ê¹Œìš”? ğŸ‘\")\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ë‹µë³€ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ Vocabulary ìƒì„±\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "print(\"ìŠ=3 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFmcm9prfbaz"
   },
   "source": [
    "- ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ì„ì˜ë¡œ ë‹¨ì–´ì¥ì— ì¶”ê°€í•˜ì—¬ ì •ìˆ˜ë¥¼ ë¶€ì—¬\n",
    "- ì´ë¯¸ ìƒì„±ëœ ë‹¨ì–´ì¥ì˜ ë²ˆí™ì™€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ 1ì´ í° ìˆ˜ë¥¼ ë¶€ì—¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "PSOqp9IlfTKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKENì˜ ë²ˆí˜¸ : [8127]\n",
      "END_TOKENì˜ ë²ˆí˜¸ : [8128]\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì— ê³ ìœ í•œ ì •ìˆ˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKENì˜ ë²ˆí˜¸ :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKENì˜ ë²ˆí˜¸ :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "hGy_yidufTFQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ê³ ë ¤í•˜ì—¬ +2ë¥¼ í•˜ì—¬ ë‹¨ì–´ì¥ì˜ í¬ê¸°ë¥¼ ì‚°ì •í•©ë‹ˆë‹¤.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWoLVitmfttf"
   },
   "source": [
    "### 2. ê° ë‹¨ì–´ë¥¼ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ì¸ì½”ë”© & íŒ¨ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LplUrKALgCxr"
   },
   "source": [
    "- ìœ„ì—ì„œ tokenizerë¥¼ ì •ì˜í•˜ê³  ë‹¨ì–´ì¥ì„ ë§Œë“¤ì—ˆë‹¤ë©´,\n",
    "- `tokenizer.encode()`ë¡œ ê° ë‹¨ì–´ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜\n",
    "- ë˜ëŠ” `tokenizer.decode()`ë¡œ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë‹¨ì–´ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "paLCsYJAfS_6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# ìƒ˜í”Œì˜ ìµœëŒ€ í—ˆìš© ê¸¸ì´ ë˜ëŠ” íŒ¨ë”© í›„ì˜ ìµœì¢… ê¸¸ì´\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "93GjrGjbfS9W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ì •ìˆ˜ ì¸ì½”ë”©, ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ëŠ” ìƒ˜í”Œ ì œê±°, íŒ¨ë”©\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ì¶”ê°€\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # ìµœëŒ€ ê¸¸ì´ 40 ì´í•˜ì¸ ê²½ìš°ì—ë§Œ ë°ì´í„°ì…‹ìœ¼ë¡œ í—ˆìš©\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # ìµœëŒ€ ê¸¸ì´ 40ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ì…‹ì„ íŒ¨ë”©\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNTXTpt0gWBX"
   },
   "source": [
    "- 40ì„ ë„˜ëŠ” ê²½ìš° í•„í„°ë§\n",
    "- í•„í„°ë§ì„ ì œì™¸í•œ ìƒ˜í”Œì˜ ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "zyrG4jRQfS6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ì¥ì˜ í¬ê¸° : 8129\n",
      "í•„í„°ë§ í›„ì˜ ì§ˆë¬¸ ìƒ˜í”Œ ê°œìˆ˜: 11823\n",
      "í•„í„°ë§ í›„ì˜ ë‹µë³€ ìƒ˜í”Œ ê°œìˆ˜: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('ë‹¨ì–´ì¥ì˜ í¬ê¸° :',(VOCAB_SIZE))\n",
    "print('í•„í„°ë§ í›„ì˜ ì§ˆë¬¸ ìƒ˜í”Œ ê°œìˆ˜: {}'.format(len(questions)))\n",
    "print('í•„í„°ë§ í›„ì˜ ë‹µë³€ ìƒ˜í”Œ ê°œìˆ˜: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5KW1VNngeW0"
   },
   "source": [
    "### 3. êµì‚¬ ê°•ìš”(Teacher Forcing) ì‚¬ìš©í•˜ê¸°\n",
    "- ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ìŒì„ tf.data.Dataset APIì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "- êµì‚¬ ê°•ìš”ë¥¼ ìœ„í•´ì„œ answers[:, : -1]ë¥¼ ë””ì½”ë”ì˜ ì…ë ¥ê°’,\n",
    "- answers[:, 1:]ë¥¼ ë””ì½”ë”ì˜ ë ˆì´ë¸”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "G_54V881fS4D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# ë””ì½”ë”ëŠ” ì´ì „ì˜ targetì„ ë‹¤ìŒì˜ inputìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "# ì´ì— ë”°ë¼ outputsì—ì„œëŠ” START_TOKENì„ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Laypt4fHQqSa"
   },
   "source": [
    "# Step 4. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n",
    "- ìœ„ ì‹¤ìŠµ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ êµ¬í˜„í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfm1F9bFi2x3"
   },
   "source": [
    "#### í¬ì§€ì…”ë„ ì¸ì½”ë”©\n",
    "- ì„ë² ë”© í–‰ë ¬ê³¼ í¬ì§€ì…”ë„ í–‰ë ¬ì´ë¼ëŠ” ë‘ í–‰ë ¬ì„ ë”í•¨ìœ¼ë¡œì¨ ê° ë‹¨ì–´ ë²¡í„°ì— ìœ„ì¹˜ ì •ë³´ë¥¼ ë”í•´ì¤€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "JytHCMY4hSbD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # ê°ë„ ë°°ì—´ ìƒì„±\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # ë°°ì—´ì˜ ì§ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” sin í•¨ìˆ˜ ì ìš©\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # ë°°ì—´ì˜ í™€ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” cosine í•¨ìˆ˜ ì ìš©\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sinê³¼ cosineì´ êµì°¨ë˜ë„ë¡ ì¬ë°°ì—´\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0])\n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvRYDepki82s"
   },
   "source": [
    "#### ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜\n",
    "1. ë‚´ì (dot product)ì„ í†µí•´ ë‹¨ì–´ ë²¡í„° ê°„ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨\n",
    "2. íŠ¹ì • ê°’ì„ ë¶„ëª¨ë¡œ ë‚˜ëˆ ì£¼ëŠ” ë°©ì‹ì„ Qì™€ Kì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•¨\n",
    "- ì´ë¥¼ ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜(Scaled Dot Product Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "TQPSnCdMhSYh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ëŠ” Qì™€ Kì˜ ë‹· í”„ë¡œë•íŠ¸\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # íŒ¨ë”©ì— ë§ˆìŠ¤í¬ ì¶”ê°€\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmaxì ìš©\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # ìµœì¢… ì–´í…ì…˜ì€ ê°€ì¤‘ì¹˜ì™€ Vì˜ ë‹· í”„ë¡œë•íŠ¸\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO43p1lQi_cW"
   },
   "source": [
    "#### ë©€í‹° í—¤ë“œ ì–´í…ì…˜\n",
    "- ë³‘ë ¬ì ìœ¼ë¡œ ëª‡ ê°œì˜ ì–´í…ì…˜ ì—°ì‚°ì„ ìˆ˜í–‰í• ì§€ë¥¼ ê²°ì •í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "- ê°ê° ë‹¤ë¥¸ ê´€ì ì—ì„œ ì–´í…ì…˜ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ í•œ ë²ˆì˜ ì–´í…ì…˜ë§Œ ìˆ˜í–‰í–ˆë‹¤ë©´ ë†“ì¹  ìˆ˜ë„ ìˆë˜ ì •ë³´ë¥¼ ìºì¹˜\n",
    "- ë‚´ë¶€ì ìœ¼ë¡œëŠ” ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "jc9ONVsGhSV8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, Vì— ê°ê° Denseë¥¼ ì ìš©í•©ë‹ˆë‹¤\n",
    "    query = self.query_dense(query)  # queryì— Dense ë ˆì´ì–´ë¥¼ ì ìš©í•©ë‹ˆë‹¤\n",
    "    key = self.key_dense(key)  # keyì— Dense ë ˆì´ì–´ë¥¼ ì ìš©í•©ë‹ˆë‹¤\n",
    "    value = self.value_dense(value)  # valueì— Dense ë ˆì´ì–´ë¥¼ ì ìš©í•©ë‹ˆë‹¤\n",
    "\n",
    "    # ë³‘ë ¬ ì—°ì‚°ì„ ìœ„í•œ ë¨¸ë¦¬ë¥¼ ì—¬ëŸ¬ ê°œ ë§Œë“­ë‹ˆë‹¤\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜ í•¨ìˆ˜\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # ì–´í…ì…˜ ì—°ì‚° í›„ì— ê° ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì—°ê²°(concatenate)í•©ë‹ˆë‹¤\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ì—ë„ Denseë¥¼ í•œ ë²ˆ ë” ì ìš©í•©ë‹ˆë‹¤\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZvQymuwjDm5"
   },
   "source": [
    "#### ë§ˆìŠ¤í‚¹\n",
    "- íŠ¹ì • ê°’ë“¤ì„ ê°€ë ¤ì„œ ì‹¤ì œ ì—°ì‚°ì— ë°©í•´ê°€ ë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ê¸°ë²•\n",
    "- íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ì–´í…ì…˜ì„ ìœ„í•´ì„œ í¬ê²Œ íŒ¨ë”© ë§ˆìŠ¤í‚¹(Padding Masking)ê³¼ ë£© ì–´í—¤ë“œ ë§ˆìŠ¤í‚¹(Look-ahead Masking)ì„ ì‚¬ìš©\n",
    "- íŒ¨ë”© ë§ˆìŠ¤í‚¹ëŠ” íŒ¨ë”© í† í°ì„ ì´ìš©í•œ ë°©ë²•<br/>\n",
    "=> ì‹¤ì œ ì˜ë¯¸ê°€ ìˆëŠ” ë‹¨ì–´ê°€ ì•„ë‹Œ 0ì€ ì œì™¸í•˜ëŠ” ë°©ì‹<br/>\n",
    "=> ì´ë¥¼ ìœ„í•´ ìˆ«ì 0ì¸ ìœ„ì¹˜ë¥¼ ì²´í¬\n",
    "<br/><br/>\n",
    "- ë£© ì–´í—¤ë“œ ë§ˆìŠ¤í‚¹ì€ ë‹¤ìŒì— ë‚˜ì˜¬ ë‹¨ì–´ë¥¼ ì°¸ê³ í•˜ì§€ ì•Šë„ë¡ ê°€ë¦¬ëŠ” ê¸°ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "yb_GV2B7hSTN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# íŒ¨ë”© ë§ˆìŠ¤í‚¹\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "W57E90RjhSQo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ë£© ì–´í—¤ë“œ ë§ˆìŠ¤í‚¹\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Se3QBcAfklvw"
   },
   "source": [
    "#### ì¸ì½”ë”\n",
    "- ì´ 2ê°œì˜ ì„œë¸Œ ì¸µìœ¼ë¡œ ì´ë£¨ì§„ë‹¤.\n",
    "    1. ì…€í”„ ì–´í…ì…˜\n",
    "        - ë©€í‹° í—¤ë“œ ì–´í…ì…˜ìœ¼ë¡œ ë³‘ë ¬ì ìœ¼ë¡œ ì´ë£¨ì–´\n",
    "    2. í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "FiDH7Pe6hSN5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ì¸ì½”ë” í•˜ë‚˜ì˜ ë ˆì´ì–´ë¥¼ í•¨ìˆ˜ë¡œ êµ¬í˜„.\n",
    "# ì´ í•˜ë‚˜ì˜ ë ˆì´ì–´ ì•ˆì—ëŠ” ë‘ ê°œì˜ ì„œë¸Œ ë ˆì´ì–´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # ì²« ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì…€í”„ ì–´í…ì…˜)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ” Dropoutê³¼ Layer Normalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : 2ê°œì˜ ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µì˜ ê²°ê³¼ëŠ” Dropoutê³¼ LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPu5vUznm7s3"
   },
   "source": [
    "#### ì¸ì½”ë” ì¸µì„ ìŒ“ì•„ ì¸ì½”ë” ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "aq2xzl1mhSLR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # íŒ¨ë”© ë§ˆìŠ¤í¬ ì‚¬ìš©\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # ì„ë² ë”© ë ˆì´ì–´\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # í¬ì§€ì…”ë„ ì¸ì½”ë”©\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layersë§Œí¼ ìŒ“ì•„ì˜¬ë¦° ì¸ì½”ë”ì˜ ì¸µ.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8GDiyRznM4W"
   },
   "source": [
    "#### ë””ì½”ë”\n",
    "- ì´ 3ê°œì˜ ì„œë¸Œ ì¸µìœ¼ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.\n",
    "    1. ì…€í”„ ì–´í…ì…˜\n",
    "    2. ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜\n",
    "    3. í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "YAnedhaGnJW-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ë””ì½”ë” í•˜ë‚˜ì˜ ë ˆì´ì–´ë¥¼ í•¨ìˆ˜ë¡œ êµ¬í˜„.\n",
    "# ì´ í•˜ë‚˜ì˜ ë ˆì´ì–´ ì•ˆì—ëŠ” ì„¸ ê°œì˜ ì„œë¸Œ ë ˆì´ì–´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # ì²« ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì…€í”„ ì–´í…ì…˜)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ” LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : ë§ˆìŠ¤í¬ë“œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ìˆ˜í–‰ (ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # ë§ˆìŠ¤í¬ë“œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ëŠ”\n",
    "  # Dropoutê³¼ LayerNormalizationì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # ì„¸ ë²ˆì§¸ ì„œë¸Œ ë ˆì´ì–´ : 2ê°œì˜ ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µì˜ ê²°ê³¼ëŠ” Dropoutê³¼ LayerNormalization ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBFNAXKxnya1"
   },
   "source": [
    "#### ë””ì½”ë” ì¸µì„ ìŒ“ì•„ ë””ì½”ë” ë§Œë“¤ê¸°\n",
    "- ì„ë² ë”© ì¸µê³¼ í¬ì§€ì…”ë„ ì¸ì½”ë”©ì„ ì—°ê²°\n",
    "- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë§Œí¼ ë””ì½”ë” ì¸µì„ ìŒ“ì•„ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” ì™„ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "2tZgSUdEnJUW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # íŒ¨ë”© ë§ˆìŠ¤í¬\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # ì„ë² ë”© ë ˆì´ì–´\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # í¬ì§€ì…”ë„ ì¸ì½”ë”©\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropoutì´ë¼ëŠ” í›ˆë ¨ì„ ë•ëŠ” í…Œí¬ë‹‰ì„ ìˆ˜í–‰\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XctqlqPdoFEW"
   },
   "source": [
    "#### íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ì •ì˜\n",
    "- ì¸ì½”ë” ì¸µ í•¨ìˆ˜ì™€ ë””ì½”ë” ì¸µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ëœìŠ¤í¬ë¨¸ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "1nh0Az8GQuHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # ì¸ì½”ë”ì—ì„œ íŒ¨ë”©ì„ ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # ë””ì½”ë”ì—ì„œ ë¯¸ë˜ì˜ í† í°ì„ ë§ˆìŠ¤í¬ í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "  # ë‚´ë¶€ì ìœ¼ë¡œ íŒ¨ë”© ë§ˆìŠ¤í¬ë„ í¬í•¨ë˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # ë‘ ë²ˆì§¸ ì–´í…ì…˜ ë¸”ë¡ì—ì„œ ì¸ì½”ë”ì˜ ë²¡í„°ë“¤ì„ ë§ˆìŠ¤í‚¹\n",
    "  # ë””ì½”ë”ì—ì„œ íŒ¨ë”©ì„ ìœ„í•œ ë§ˆìŠ¤í¬\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # ì¸ì½”ë”\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # ë””ì½”ë”\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # ì™„ì „ì—°ê²°ì¸µ\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3viOk3goN8n"
   },
   "source": [
    "#### íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ìƒì„±\n",
    "- `num_layers`, `d_model`, `units`ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "cs7JyygShHJv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3135232     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3662592     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8129)   2089153     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,886,977\n",
      "Trainable params: 8,886,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "NUM_LAYERS = 2 # ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì¸µì˜ ê°œìˆ˜\n",
    "D_MODEL = 256 # ì¸ì½”ë”ì™€ ë””ì½”ë” ë‚´ë¶€ì˜ ì…, ì¶œë ¥ì˜ ê³ ì • ì°¨ì›\n",
    "NUM_HEADS = 8 # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì—ì„œì˜ í—¤ë“œ ìˆ˜\n",
    "UNITS = 512 # í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ì˜ ì€ë‹‰ì¸µì˜ í¬ê¸°\n",
    "DROPOUT = 0.1 # ë“œë¡­ì•„ì›ƒì˜ ë¹„ìœ¨\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZXU1NXeoamQ"
   },
   "source": [
    "#### ì†ì‹¤ í•¨ìˆ˜\n",
    "- ë ˆì´ë¸”ì¸ ì‹œí€€ìŠ¤ì— íŒ¨ë”©ì´ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, lossë¥¼ ê³„ì‚°í•  ë•Œ íŒ¨ë”© ë§ˆìŠ¤í‚¹ì„ ì ìš©í•´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "RxfZbjMyhHHv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWWwncuIouOM"
   },
   "source": [
    "#### ì»¤ìŠ¤í…€ ëœ í•™ìŠµë¥ \n",
    "- ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§(Custom Learing rate Scheduling)\n",
    "    - í•™ìŠµ ì´ˆê¸°ì— lrì„ ê¸‰ê²©íˆ ë†’ì˜€ë‹¤ê°€,\n",
    "    - ì´í›„ trian stepì´ ì§„í–‰ë¨ì— ë”°ë¼ ì„œì„œíˆ ë‚®ì¶”ì–´ê°€ë©° ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "GLTA8sm0hHFC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3WgII37pEUb"
   },
   "source": [
    "- ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "G9Snbu5YhHCb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "OZpXJkOZhG_4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1r8LeJgXhG9O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 15s 54ms/step - loss: 1.4483 - accuracy: 0.0272\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 1.1796 - accuracy: 0.0493\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 1.0037 - accuracy: 0.0505\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.9247 - accuracy: 0.0545\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.8658 - accuracy: 0.0577\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.8060 - accuracy: 0.0619\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.7398 - accuracy: 0.0681\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.6667 - accuracy: 0.0759\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5876 - accuracy: 0.0845\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5058 - accuracy: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa842c7aa00>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqFKKeQ4Quez"
   },
   "source": [
    "# Step 5. ëª¨ë¸ í‰ê°€í•˜ê¸°\n",
    "- Step 1ì—ì„œ ì„ íƒí•œ ì „ì²˜ë¦¬ ë°©ë²•ì„ ê³ ë ¤í•˜ì—¬ ì…ë ¥ëœ ë¬¸ì¥ì— ëŒ€í•´ì„œ ëŒ€ë‹µì„ ì–»ëŠ” ì˜ˆì¸¡ í•¨ìˆ˜ë¥¼ ë§Œë“ ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "LyHtXGE3Q0e_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # ì…ë ¥ëœ ë¬¸ì¥ì„ ì •ìˆ˜ ì¸ì½”ë”© í›„, ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í°ì„ ì•ë’¤ë¡œ ì¶”ê°€.\n",
    "  # ex) Where have you been? â†’ [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # ë””ì½”ë”ì˜ í˜„ì¬ê¹Œì§€ì˜ ì˜ˆì¸¡í•œ ì¶œë ¥ ì‹œí€€ìŠ¤ê°€ ì§€ì†ì ìœ¼ë¡œ ì €ì¥ë˜ëŠ” ë³€ìˆ˜.\n",
    "  # ì²˜ìŒì—ëŠ” ì˜ˆì¸¡í•œ ë‚´ìš©ì´ ì—†ìŒìœ¼ë¡œ ì‹œì‘ í† í°ë§Œ ë³„ë„ ì €ì¥. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # ë””ì½”ë”ì˜ ì¸í¼ëŸ°ìŠ¤ ë‹¨ê³„\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # ë””ì½”ë”ëŠ” ìµœëŒ€ MAX_LENGTHì˜ ê¸¸ì´ë§Œí¼ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ì„ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # í˜„ì¬ ì˜ˆì¸¡í•œ ë‹¨ì–´ì˜ ì •ìˆ˜\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # ë§Œì•½ í˜„ì¬ ì˜ˆì¸¡í•œ ë‹¨ì–´ê°€ ì¢…ë£Œ í† í°ì´ë¼ë©´ forë¬¸ì„ ì¢…ë£Œ\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # ì˜ˆì¸¡í•œ ë‹¨ì–´ë“¤ì€ ì§€ì†ì ìœ¼ë¡œ output_sequenceì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "    # ì´ output_sequenceëŠ” ë‹¤ì‹œ ë””ì½”ë”ì˜ ì…ë ¥ì´ ë©ë‹ˆë‹¤.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ì„ì˜ì˜ ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•˜ì—¬ decoder_inference() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì±—ë´‡ì˜ ëŒ€ë‹µì„ ì–»ëŠ” sentence_generation() í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # ì…ë ¥ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë””ì½”ë”ë¥¼ ë™ì‘ ì‹œì¼œ ì˜ˆì¸¡ëœ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë¦¬í„´ë°›ìŠµë‹ˆë‹¤.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # ì •ìˆ˜ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('ì…ë ¥ : {}'.format(sentence))\n",
    "    print('ì¶œë ¥ : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [\n",
    "    \"ì˜¤ëŠ˜ ë­ ë¨¹ì„ê¹Œìš”?\",\n",
    "    \"ìì‚´í•˜ê³  ì‹¶ì–´\",\n",
    "    \"ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?\",\n",
    "    \"ë„Œ ëˆ„êµ¬ì•¼?\",\n",
    "    \"ì¸ìƒì€ ë­˜ê¹Œ\",\n",
    "    \"ë„ˆ ë­ ì¢‹ì•„í•´?\",\n",
    "    \"ê³µë¶€ ì¢€ ëŒ€ì‹ í•´ì¤˜\",\n",
    "    \"ì‚¬ë‘í•´\",\n",
    "    \"í”¼ê³¤í•´\",\n",
    "    \"ê·¸ë™ì•ˆ ì¦ê±°ì› ì–´\",\n",
    "    \"ìë‹ˆ?\",\n",
    "    \"í˜ë“¤ì–´\",\n",
    "    \"ë†€ì•„ì¤˜\",\n",
    "    \"ì¢…êµê°€ ë­ì•¼?\",\n",
    "    \"ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜\",\n",
    "    \"ì˜¤ëœë§Œì´ì•¼\",\n",
    "    \"ë„ˆëŠ” ì–´ë–»ê²Œ ê¸°ë¶„ì „í™˜í•´?\",\n",
    "    \"ë„ˆì˜ ê¿ˆì´ ë­ì•¼?\",\n",
    "    \"ë„ˆëŠ” í–‰ë³µí•´?\",\n",
    "    \"ì›ƒì–´ì¤˜\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(question_list):\n",
    "    for question in question_list:\n",
    "        sentence_generation(question)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs = 10 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ : ì˜¤ëŠ˜ ë­ ë¨¹ì„ê¹Œìš”?\n",
      "ì¶œë ¥ : ì˜ ì°¾ì•„ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ìì‚´í•˜ê³  ì‹¶ì–´\n",
      "ì¶œë ¥ : ì˜ ì°¾ì•„ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?\n",
      "ì¶œë ¥ : ê·¸ê²Œ ìµœê³ ì£  .\n",
      "\n",
      "ì…ë ¥ : ë„Œ ëˆ„êµ¬ì•¼?\n",
      "ì¶œë ¥ : ë‹¤ë¥¸ ê³³ì— ì“°ë ¤ê³  ìš´ì„ ì•„ê»´ë’€ë‚˜ë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì¸ìƒì€ ë­˜ê¹Œ\n",
      "ì¶œë ¥ : ì €ë„ ì¢‹ì•„í•´ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆ ë­ ì¢‹ì•„í•´?\n",
      "ì¶œë ¥ : ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .\n",
      "\n",
      "ì…ë ¥ : ê³µë¶€ ì¢€ ëŒ€ì‹ í•´ì¤˜\n",
      "ì¶œë ¥ : ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì‚¬ë‘í•´\n",
      "ì¶œë ¥ : ì¡°ê¸ˆë§Œ ë“œì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : í”¼ê³¤í•´\n",
      "ì¶œë ¥ : ê³§ ë°©í•™ì´ì˜ˆìš” .\n",
      "\n",
      "ì…ë ¥ : ê·¸ë™ì•ˆ ì¦ê±°ì› ì–´\n",
      "ì¶œë ¥ : ê°ê¸° ì¡°ì‹¬í•˜ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ìë‹ˆ?\n",
      "ì¶œë ¥ : ë§›ìˆê²Œ ë“œì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : í˜ë“¤ì–´\n",
      "ì¶œë ¥ : ì¡°ê¸ˆë§Œ ë” ë²„í…¨ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ë†€ì•„ì¤˜\n",
      "ì¶œë ¥ : ê°™ì´ ë†€ì•„ìš” .\n",
      "\n",
      "ì…ë ¥ : ì¢…êµê°€ ë­ì•¼?\n",
      "ì¶œë ¥ : í™”ì¥ì‹¤ ê°€ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜\n",
      "ì¶œë ¥ : ë§›ìˆëŠ” ê±° ë“œì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëœë§Œì´ì•¼\n",
      "ì¶œë ¥ : ë” ì¢‹ì€ ì‚¬ëŒ ë§Œë‚  ìˆ˜ ìˆì„ ê±°ì˜ˆìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” ì–´ë–»ê²Œ ê¸°ë¶„ì „í™˜í•´?\n",
      "ì¶œë ¥ : ë‹¤ë¥¸ ê³³ì— ì“°ë ¤ê³  ìš´ì„ ì•„ê»´ë’€ë‚˜ë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆì˜ ê¿ˆì´ ë­ì•¼?\n",
      "ì¶œë ¥ : ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” í–‰ë³µí•´?\n",
      "ì¶œë ¥ : ì˜ ì°¾ì•„ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì›ƒì–´ì¤˜\n",
      "ì¶œë ¥ : ì˜¤ëŠ˜ ì¼ì° ì£¼ë¬´ì„¸ìš” .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers(question_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs = 300 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.4235 - accuracy: 0.1039\n",
      "Epoch 2/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.3435 - accuracy: 0.1151\n",
      "Epoch 3/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.2697 - accuracy: 0.1260\n",
      "Epoch 4/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.2058 - accuracy: 0.1359\n",
      "Epoch 5/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.1519 - accuracy: 0.1450\n",
      "Epoch 6/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.1092 - accuracy: 0.1532\n",
      "Epoch 7/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0805 - accuracy: 0.1582\n",
      "Epoch 8/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0626 - accuracy: 0.1613\n",
      "Epoch 9/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0517 - accuracy: 0.1635\n",
      "Epoch 10/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0457 - accuracy: 0.1644\n",
      "Epoch 11/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0433 - accuracy: 0.1646\n",
      "Epoch 12/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0416 - accuracy: 0.1647\n",
      "Epoch 13/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0374 - accuracy: 0.1658\n",
      "Epoch 14/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0331 - accuracy: 0.1668\n",
      "Epoch 15/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0290 - accuracy: 0.1677\n",
      "Epoch 16/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0254 - accuracy: 0.1685\n",
      "Epoch 17/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0227 - accuracy: 0.1694\n",
      "Epoch 18/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0209 - accuracy: 0.1697\n",
      "Epoch 19/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0194 - accuracy: 0.1701\n",
      "Epoch 20/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0177 - accuracy: 0.1706\n",
      "Epoch 21/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0164 - accuracy: 0.1709\n",
      "Epoch 22/300\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0143 - accuracy: 0.1714\n",
      "Epoch 23/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0141 - accuracy: 0.1716\n",
      "Epoch 24/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0127 - accuracy: 0.1719\n",
      "Epoch 25/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0119 - accuracy: 0.1721\n",
      "Epoch 26/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0115 - accuracy: 0.1722\n",
      "Epoch 27/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0108 - accuracy: 0.1723\n",
      "Epoch 28/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0102 - accuracy: 0.1725\n",
      "Epoch 29/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0091 - accuracy: 0.1728\n",
      "Epoch 30/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0090 - accuracy: 0.1728\n",
      "Epoch 31/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0089 - accuracy: 0.1728\n",
      "Epoch 32/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0084 - accuracy: 0.1731\n",
      "Epoch 33/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0075 - accuracy: 0.1732\n",
      "Epoch 34/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0074 - accuracy: 0.1732\n",
      "Epoch 35/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0075 - accuracy: 0.1732\n",
      "Epoch 36/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0070 - accuracy: 0.1732\n",
      "Epoch 37/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0068 - accuracy: 0.1733\n",
      "Epoch 38/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0066 - accuracy: 0.1733\n",
      "Epoch 39/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0061 - accuracy: 0.1735\n",
      "Epoch 40/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0064 - accuracy: 0.1734\n",
      "Epoch 41/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0058 - accuracy: 0.1735\n",
      "Epoch 42/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0057 - accuracy: 0.1736\n",
      "Epoch 43/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0055 - accuracy: 0.1736\n",
      "Epoch 44/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0053 - accuracy: 0.1737\n",
      "Epoch 45/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0055 - accuracy: 0.1736\n",
      "Epoch 46/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0048 - accuracy: 0.1738\n",
      "Epoch 47/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0046 - accuracy: 0.1738\n",
      "Epoch 48/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0049 - accuracy: 0.1738\n",
      "Epoch 49/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0047 - accuracy: 0.1738\n",
      "Epoch 50/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0046 - accuracy: 0.1738\n",
      "Epoch 51/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0041 - accuracy: 0.1738\n",
      "Epoch 52/300\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.0043 - accuracy: 0.1739\n",
      "Epoch 53/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0042 - accuracy: 0.1738\n",
      "Epoch 54/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0043 - accuracy: 0.1739\n",
      "Epoch 55/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0038 - accuracy: 0.1739\n",
      "Epoch 56/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0041 - accuracy: 0.1739\n",
      "Epoch 57/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0039 - accuracy: 0.1740\n",
      "Epoch 58/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0037 - accuracy: 0.1740\n",
      "Epoch 59/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0036 - accuracy: 0.1740\n",
      "Epoch 60/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0035 - accuracy: 0.1740\n",
      "Epoch 61/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0034 - accuracy: 0.1740\n",
      "Epoch 62/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1741\n",
      "Epoch 63/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0032 - accuracy: 0.1740\n",
      "Epoch 64/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0032 - accuracy: 0.1740\n",
      "Epoch 65/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0032 - accuracy: 0.1740\n",
      "Epoch 66/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0029 - accuracy: 0.1741\n",
      "Epoch 67/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0030 - accuracy: 0.1741\n",
      "Epoch 68/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0030 - accuracy: 0.1741\n",
      "Epoch 69/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1741\n",
      "Epoch 70/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1741\n",
      "Epoch 71/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1741\n",
      "Epoch 72/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1741\n",
      "Epoch 73/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1741\n",
      "Epoch 74/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1741\n",
      "Epoch 75/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1742\n",
      "Epoch 76/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1741\n",
      "Epoch 77/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0025 - accuracy: 0.1741\n",
      "Epoch 78/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1742\n",
      "Epoch 79/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0023 - accuracy: 0.1742\n",
      "Epoch 80/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1741\n",
      "Epoch 81/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0023 - accuracy: 0.1742\n",
      "Epoch 82/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0022 - accuracy: 0.1741\n",
      "Epoch 83/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0021 - accuracy: 0.1742\n",
      "Epoch 84/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1742\n",
      "Epoch 85/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1742\n",
      "Epoch 86/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1742\n",
      "Epoch 87/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1742\n",
      "Epoch 88/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1742\n",
      "Epoch 89/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1742\n",
      "Epoch 90/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 91/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1742\n",
      "Epoch 92/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1742\n",
      "Epoch 93/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1742\n",
      "Epoch 94/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1742\n",
      "Epoch 95/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1743\n",
      "Epoch 96/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1742\n",
      "Epoch 97/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1743\n",
      "Epoch 98/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 99/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 100/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 101/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 102/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1742\n",
      "Epoch 103/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 104/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 105/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1743\n",
      "Epoch 106/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 107/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1742\n",
      "Epoch 108/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1743\n",
      "Epoch 109/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 110/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1743\n",
      "Epoch 111/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 112/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1743\n",
      "Epoch 113/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0015 - accuracy: 0.1743\n",
      "Epoch 114/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 115/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1742\n",
      "Epoch 116/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1743\n",
      "Epoch 117/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 118/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 119/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 120/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 121/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 122/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1743\n",
      "Epoch 123/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 124/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 125/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 126/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 127/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 128/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 129/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 130/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 131/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 132/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 133/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 134/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 135/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 136/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 137/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 138/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 139/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 140/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1743\n",
      "Epoch 141/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 142/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 143/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 144/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 145/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1743\n",
      "Epoch 146/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 147/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 148/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 149/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 150/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 151/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 152/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 153/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 154/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 155/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 156/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 157/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 158/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 159/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 160/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 161/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 162/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 163/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 164/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1743\n",
      "Epoch 165/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 166/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 167/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 168/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 169/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 170/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 171/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 172/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 173/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 174/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 175/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 176/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 177/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 178/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.5914e-04 - accuracy: 0.1743\n",
      "Epoch 179/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 180/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 181/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 182/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.9609e-04 - accuracy: 0.1743\n",
      "Epoch 183/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 184/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 185/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 186/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1744\n",
      "Epoch 187/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 188/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 189/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 190/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 191/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 192/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 193/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1744\n",
      "Epoch 194/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.7468e-04 - accuracy: 0.1744\n",
      "Epoch 195/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 196/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 197/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 198/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4279e-04 - accuracy: 0.1743\n",
      "Epoch 199/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 200/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.9967e-04 - accuracy: 0.1744\n",
      "Epoch 201/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.6452e-04 - accuracy: 0.1743\n",
      "Epoch 202/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.9845e-04 - accuracy: 0.1743\n",
      "Epoch 203/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.5206e-04 - accuracy: 0.1743\n",
      "Epoch 204/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 205/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 206/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 207/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.6765e-04 - accuracy: 0.1743\n",
      "Epoch 208/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3686e-04 - accuracy: 0.1744\n",
      "Epoch 209/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.2356e-04 - accuracy: 0.1743\n",
      "Epoch 210/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.7806e-04 - accuracy: 0.1743\n",
      "Epoch 211/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 212/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 213/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.0196e-04 - accuracy: 0.1743\n",
      "Epoch 214/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.2414e-04 - accuracy: 0.1744\n",
      "Epoch 215/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 216/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 217/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5477e-04 - accuracy: 0.1744\n",
      "Epoch 218/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.3096e-04 - accuracy: 0.1744\n",
      "Epoch 219/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9997e-04 - accuracy: 0.1744\n",
      "Epoch 220/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 221/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1743\n",
      "Epoch 222/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.0365e-04 - accuracy: 0.1744\n",
      "Epoch 223/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.3480e-04 - accuracy: 0.1744\n",
      "Epoch 224/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4625e-04 - accuracy: 0.1744\n",
      "Epoch 225/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.6410e-04 - accuracy: 0.1743\n",
      "Epoch 226/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4909e-04 - accuracy: 0.1743\n",
      "Epoch 227/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.0576e-04 - accuracy: 0.1743\n",
      "Epoch 228/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7969e-04 - accuracy: 0.1743\n",
      "Epoch 229/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1744\n",
      "Epoch 230/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.2501e-04 - accuracy: 0.1744\n",
      "Epoch 231/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7979e-04 - accuracy: 0.1743\n",
      "Epoch 232/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4682e-04 - accuracy: 0.1743\n",
      "Epoch 233/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4532e-04 - accuracy: 0.1743\n",
      "Epoch 234/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9359e-04 - accuracy: 0.1744\n",
      "Epoch 235/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.2685e-04 - accuracy: 0.1743\n",
      "Epoch 236/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4763e-04 - accuracy: 0.1743\n",
      "Epoch 237/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.4991e-04 - accuracy: 0.1744\n",
      "Epoch 238/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7268e-04 - accuracy: 0.1744\n",
      "Epoch 239/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5107e-04 - accuracy: 0.1743\n",
      "Epoch 240/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.7749e-04 - accuracy: 0.1743\n",
      "Epoch 241/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.1859e-04 - accuracy: 0.1744\n",
      "Epoch 242/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7036e-04 - accuracy: 0.1744\n",
      "Epoch 243/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9262e-04 - accuracy: 0.1743\n",
      "Epoch 244/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5798e-04 - accuracy: 0.1744\n",
      "Epoch 245/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0011 - accuracy: 0.1743\n",
      "Epoch 246/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.9897e-04 - accuracy: 0.1743\n",
      "Epoch 247/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.4246e-04 - accuracy: 0.1744\n",
      "Epoch 248/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.1045e-04 - accuracy: 0.1744\n",
      "Epoch 249/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 9.7061e-04 - accuracy: 0.1743\n",
      "Epoch 250/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 9.7740e-04 - accuracy: 0.1743\n",
      "Epoch 251/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7501e-04 - accuracy: 0.1743\n",
      "Epoch 252/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 9.2355e-04 - accuracy: 0.1744\n",
      "Epoch 253/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 9.3698e-04 - accuracy: 0.1744\n",
      "Epoch 254/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4356e-04 - accuracy: 0.1743\n",
      "Epoch 255/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4858e-04 - accuracy: 0.1743\n",
      "Epoch 256/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8740e-04 - accuracy: 0.1744\n",
      "Epoch 257/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4923e-04 - accuracy: 0.1744\n",
      "Epoch 258/300\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 9.7824e-04 - accuracy: 0.1743\n",
      "Epoch 259/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.6119e-04 - accuracy: 0.1743\n",
      "Epoch 260/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.8759e-04 - accuracy: 0.1743\n",
      "Epoch 261/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5989e-04 - accuracy: 0.1744\n",
      "Epoch 262/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3077e-04 - accuracy: 0.1744\n",
      "Epoch 263/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9115e-04 - accuracy: 0.1743\n",
      "Epoch 264/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7752e-04 - accuracy: 0.1743\n",
      "Epoch 265/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7084e-04 - accuracy: 0.1744\n",
      "Epoch 266/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7827e-04 - accuracy: 0.1743\n",
      "Epoch 267/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.1156e-04 - accuracy: 0.1743\n",
      "Epoch 268/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1743\n",
      "Epoch 269/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7087e-04 - accuracy: 0.1744\n",
      "Epoch 270/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9421e-04 - accuracy: 0.1744\n",
      "Epoch 271/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.3561e-04 - accuracy: 0.1744\n",
      "Epoch 272/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0348e-04 - accuracy: 0.1744\n",
      "Epoch 273/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5747e-04 - accuracy: 0.1744\n",
      "Epoch 274/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.8542e-04 - accuracy: 0.1743\n",
      "Epoch 275/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0664e-04 - accuracy: 0.1743\n",
      "Epoch 276/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6398e-04 - accuracy: 0.1744\n",
      "Epoch 277/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.4092e-04 - accuracy: 0.1744\n",
      "Epoch 278/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.6176e-04 - accuracy: 0.1743\n",
      "Epoch 279/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3429e-04 - accuracy: 0.1744\n",
      "Epoch 280/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.0127e-04 - accuracy: 0.1743\n",
      "Epoch 281/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3061e-04 - accuracy: 0.1744\n",
      "Epoch 282/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3880e-04 - accuracy: 0.1743\n",
      "Epoch 283/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9766e-04 - accuracy: 0.1743\n",
      "Epoch 284/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0968e-04 - accuracy: 0.1743\n",
      "Epoch 285/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7964e-04 - accuracy: 0.1744\n",
      "Epoch 286/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4960e-04 - accuracy: 0.1744\n",
      "Epoch 287/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.6018e-04 - accuracy: 0.1743\n",
      "Epoch 288/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7327e-04 - accuracy: 0.1743\n",
      "Epoch 289/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.0264e-04 - accuracy: 0.1744\n",
      "Epoch 290/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.9368e-04 - accuracy: 0.1743\n",
      "Epoch 291/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5923e-04 - accuracy: 0.1744\n",
      "Epoch 292/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8874e-04 - accuracy: 0.1744\n",
      "Epoch 293/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4975e-04 - accuracy: 0.1744\n",
      "Epoch 294/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8609e-04 - accuracy: 0.1744\n",
      "Epoch 295/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5044e-04 - accuracy: 0.1744\n",
      "Epoch 296/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3584e-04 - accuracy: 0.1743\n",
      "Epoch 297/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1453e-04 - accuracy: 0.1744\n",
      "Epoch 298/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0720e-04 - accuracy: 0.1744\n",
      "Epoch 299/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 9.5890e-04 - accuracy: 0.1743\n",
      "Epoch 300/300\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0652e-04 - accuracy: 0.1743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8041ffbb0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ : ì˜¤ëŠ˜ ë­ ë¨¹ì„ê¹Œìš”?\n",
      "ì¶œë ¥ : ì¢€ ë¨¹ì–´ë„ ê´œì°®ì•„ìš” .\n",
      "\n",
      "ì…ë ¥ : ìì‚´í•˜ê³  ì‹¶ì–´\n",
      "ì¶œë ¥ : ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?\n",
      "ì¶œë ¥ : ë”± ì˜ ë§Œë‚¬ë„¤ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„Œ ëˆ„êµ¬ì•¼?\n",
      "ì¶œë ¥ : ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤ .\n",
      "\n",
      "ì…ë ¥ : ì¸ìƒì€ ë­˜ê¹Œ\n",
      "ì¶œë ¥ : ê½ƒê¸¸ë§Œ ê±·ê¸¸ ë°”ëë‹ˆë‹¤ .\n",
      "\n",
      "ì…ë ¥ : ë„ˆ ë­ ì¢‹ì•„í•´?\n",
      "ì¶œë ¥ : ê³ ë°±í•˜ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ê³µë¶€ ì¢€ ëŒ€ì‹ í•´ì¤˜\n",
      "ì¶œë ¥ : ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì‚¬ë‘í•´\n",
      "ì¶œë ¥ : í•˜ëŠ˜ ë§Œí¼ ë•… ë§Œí¼ ì‚¬ë‘í•´ìš” .\n",
      "\n",
      "ì…ë ¥ : í”¼ê³¤í•´\n",
      "ì¶œë ¥ : ìš”ì¦˜ ë°”ìœê°€ë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ê·¸ë™ì•ˆ ì¦ê±°ì› ì–´\n",
      "ì¶œë ¥ : í•  ì¼ì´ ë§ì€ë° ì•ˆí•˜ëŠ” ê²ƒì´ìš” .\n",
      "\n",
      "ì…ë ¥ : ìë‹ˆ?\n",
      "ì¶œë ¥ : ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : í˜ë“¤ì–´\n",
      "ì¶œë ¥ : ì§€ê¸ˆì€ í˜ë“¤ê² ì§€ë§Œ ì¡°ê¸ˆë§Œ ë” ê²¬ëŒë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ë†€ì•„ì¤˜\n",
      "ì¶œë ¥ : ì§€ê¸ˆ ê·¸ëŸ¬ê³  ìˆì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì¢…êµê°€ ë­ì•¼?\n",
      "ì¶œë ¥ : ì¢…êµê°€ í° ë¬¸ì œê°€ ë˜ê¸°ë„ í•˜ì£  .\n",
      "\n",
      "ì…ë ¥ : ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜\n",
      "ì¶œë ¥ : ëƒ‰ì¥ê³  íŒŒë¨¹ê¸° í•´ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëœë§Œì´ì•¼\n",
      "ì¶œë ¥ : ì˜¤ëœë§Œì´ì—ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” ì–´ë–»ê²Œ ê¸°ë¶„ì „í™˜í•´?\n",
      "ì¶œë ¥ : ì•„ì§ ì•ˆ ììš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆì˜ ê¿ˆì´ ë­ì•¼?\n",
      "ì¶œë ¥ : ì²œì²œíˆ ì§€ì›Œì§ˆ ê±°ì˜ˆìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” í–‰ë³µí•´?\n",
      "ì¶œë ¥ : ì €ëŠ” ë‘˜ì´ ê°€ëŠ” ê²Œ ì¢‹ì•„ìš” .\n",
      "\n",
      "ì…ë ¥ : ì›ƒì–´ì¤˜\n",
      "ì¶œë ¥ : ê¸°ëŒ€ë¥¼ ì¡°ê¸ˆì”© ë²„ë ¤ë³´ì„¸ìš” .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers(question_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs = 500 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7225e-04 - accuracy: 0.1744\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6448e-04 - accuracy: 0.1744\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.2344e-04 - accuracy: 0.1744\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.5226e-04 - accuracy: 0.1744\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.3913e-04 - accuracy: 0.1743\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6703e-04 - accuracy: 0.1744\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3604e-04 - accuracy: 0.1744\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5545e-04 - accuracy: 0.1744\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4816e-04 - accuracy: 0.1743\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1800e-04 - accuracy: 0.1743\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1111e-04 - accuracy: 0.1744\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3347e-04 - accuracy: 0.1744\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0655e-04 - accuracy: 0.1743\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3867e-04 - accuracy: 0.1744\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2302e-04 - accuracy: 0.1744\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1822e-04 - accuracy: 0.1743\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.8453e-04 - accuracy: 0.1744\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4315e-04 - accuracy: 0.1744\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7715e-04 - accuracy: 0.1743\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4064e-04 - accuracy: 0.1744\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3530e-04 - accuracy: 0.1744\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1528e-04 - accuracy: 0.1744\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7714e-04 - accuracy: 0.1743\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6449e-04 - accuracy: 0.1744\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7003e-04 - accuracy: 0.1743\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5941e-04 - accuracy: 0.1744\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5485e-04 - accuracy: 0.1744\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2598e-04 - accuracy: 0.1743\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 8.2225e-04 - accuracy: 0.1744\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9074e-04 - accuracy: 0.1744\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1706e-04 - accuracy: 0.1744\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2059e-04 - accuracy: 0.1743\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.7748e-04 - accuracy: 0.1743\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4449e-04 - accuracy: 0.1744\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3746e-04 - accuracy: 0.1744\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6099e-04 - accuracy: 0.1744\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9429e-04 - accuracy: 0.1744\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7642e-04 - accuracy: 0.1744\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9596e-04 - accuracy: 0.1743\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1028e-04 - accuracy: 0.1744\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1851e-04 - accuracy: 0.1743\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2060e-04 - accuracy: 0.1743\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.8999e-04 - accuracy: 0.1743\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3587e-04 - accuracy: 0.1744\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4374e-04 - accuracy: 0.1744\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6498e-04 - accuracy: 0.1744\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7417e-04 - accuracy: 0.1744\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4045e-04 - accuracy: 0.1744\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9961e-04 - accuracy: 0.1743\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4167e-04 - accuracy: 0.1744\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2415e-04 - accuracy: 0.1744\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5441e-04 - accuracy: 0.1744\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6805e-04 - accuracy: 0.1744\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1080e-04 - accuracy: 0.1744\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1779e-04 - accuracy: 0.1744\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0257e-04 - accuracy: 0.1744\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1437e-04 - accuracy: 0.1744\n",
      "Epoch 58/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.1735e-04 - accuracy: 0.1744\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.8644e-04 - accuracy: 0.1744\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.9002e-04 - accuracy: 0.1744\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4269e-04 - accuracy: 0.1744\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.5282e-04 - accuracy: 0.1743\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9296e-04 - accuracy: 0.1743\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0926e-04 - accuracy: 0.1744\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2871e-04 - accuracy: 0.1744\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1038e-04 - accuracy: 0.1744\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1542e-04 - accuracy: 0.1744\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5263e-04 - accuracy: 0.1743\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6655e-04 - accuracy: 0.1744\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8911e-04 - accuracy: 0.1744\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4488e-04 - accuracy: 0.1744\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.5349e-04 - accuracy: 0.1744\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3328e-04 - accuracy: 0.1744\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3419e-04 - accuracy: 0.1744\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3082e-04 - accuracy: 0.1744\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0744e-04 - accuracy: 0.1743\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9199e-04 - accuracy: 0.1744\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4580e-04 - accuracy: 0.1744\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8482e-04 - accuracy: 0.1743\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2035e-04 - accuracy: 0.1743\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6098e-04 - accuracy: 0.1744\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9678e-04 - accuracy: 0.1744\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0691e-04 - accuracy: 0.1744\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4763e-04 - accuracy: 0.1743\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3442e-04 - accuracy: 0.1744\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8112e-04 - accuracy: 0.1744\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0750e-04 - accuracy: 0.1744\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4175e-04 - accuracy: 0.1744\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.5866e-04 - accuracy: 0.1744\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.9934e-04 - accuracy: 0.1744\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.7558e-04 - accuracy: 0.1743\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9553e-04 - accuracy: 0.1744\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0518e-04 - accuracy: 0.1743\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.3395e-04 - accuracy: 0.1744\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0158e-04 - accuracy: 0.1744\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9625e-04 - accuracy: 0.1744\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4238e-04 - accuracy: 0.1743\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2185e-04 - accuracy: 0.1744\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2149e-04 - accuracy: 0.1743\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7976e-04 - accuracy: 0.1744\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3069e-04 - accuracy: 0.1744\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6716e-04 - accuracy: 0.1744\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2252e-04 - accuracy: 0.1743\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2436e-04 - accuracy: 0.1744\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9935e-04 - accuracy: 0.1744\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8681e-04 - accuracy: 0.1744\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2409e-04 - accuracy: 0.1744\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9646e-04 - accuracy: 0.1743\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3682e-04 - accuracy: 0.1744\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8343e-04 - accuracy: 0.1744\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0149e-04 - accuracy: 0.1744\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9246e-04 - accuracy: 0.1744\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8535e-04 - accuracy: 0.1744\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.4778e-04 - accuracy: 0.1743\n",
      "Epoch 115/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0154e-04 - accuracy: 0.1744\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6220e-04 - accuracy: 0.1744\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1032e-04 - accuracy: 0.1744\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5276e-04 - accuracy: 0.1744\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8612e-04 - accuracy: 0.1744\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5741e-04 - accuracy: 0.1744\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9349e-04 - accuracy: 0.1744\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0327e-04 - accuracy: 0.1744\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4636e-04 - accuracy: 0.1744\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0494e-04 - accuracy: 0.1744\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1804e-04 - accuracy: 0.1744\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9728e-04 - accuracy: 0.1744\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5756e-04 - accuracy: 0.1744\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9882e-04 - accuracy: 0.1744\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9719e-04 - accuracy: 0.1744\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1557e-04 - accuracy: 0.1744\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4233e-04 - accuracy: 0.1744\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2490e-04 - accuracy: 0.1744\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.2063e-04 - accuracy: 0.1743\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8292e-04 - accuracy: 0.1743\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2178e-04 - accuracy: 0.1744\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5667e-04 - accuracy: 0.1744\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6331e-04 - accuracy: 0.1744\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.9245e-04 - accuracy: 0.1744\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2086e-04 - accuracy: 0.1744\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4016e-04 - accuracy: 0.1744\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5044e-04 - accuracy: 0.1744\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9035e-04 - accuracy: 0.1744\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4725e-04 - accuracy: 0.1744\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3108e-04 - accuracy: 0.1744\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2639e-04 - accuracy: 0.1744\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5698e-04 - accuracy: 0.1744\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7087e-04 - accuracy: 0.1744\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5084e-04 - accuracy: 0.1744\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9789e-04 - accuracy: 0.1744\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0544e-04 - accuracy: 0.1744\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1336e-04 - accuracy: 0.1744\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4172e-04 - accuracy: 0.1744\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1625e-04 - accuracy: 0.1744\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1336e-04 - accuracy: 0.1744\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8773e-04 - accuracy: 0.1744\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3839e-04 - accuracy: 0.1744\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7771e-04 - accuracy: 0.1744\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0677e-04 - accuracy: 0.1744\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3987e-04 - accuracy: 0.1744\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0495e-04 - accuracy: 0.1744\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9656e-04 - accuracy: 0.1743\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5337e-04 - accuracy: 0.1744\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0056e-04 - accuracy: 0.1744\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0394e-04 - accuracy: 0.1744\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7938e-04 - accuracy: 0.1744\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1843e-04 - accuracy: 0.1744\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5967e-04 - accuracy: 0.1744\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2124e-04 - accuracy: 0.1744\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9773e-04 - accuracy: 0.1744\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6523e-04 - accuracy: 0.1744\n",
      "Epoch 171/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0549e-04 - accuracy: 0.1744\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8581e-04 - accuracy: 0.1743\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1073e-04 - accuracy: 0.1744\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7906e-04 - accuracy: 0.1744\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3879e-04 - accuracy: 0.1744\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8262e-04 - accuracy: 0.1744\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2895e-04 - accuracy: 0.1743\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5915e-04 - accuracy: 0.1744\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2840e-04 - accuracy: 0.1744\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2994e-04 - accuracy: 0.1744\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.7549e-04 - accuracy: 0.1744\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6222e-04 - accuracy: 0.1744\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.1015e-04 - accuracy: 0.1744\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7918e-04 - accuracy: 0.1744\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8974e-04 - accuracy: 0.1744\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3559e-04 - accuracy: 0.1744\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6460e-04 - accuracy: 0.1744\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5917e-04 - accuracy: 0.1744\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4875e-04 - accuracy: 0.1744\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5903e-04 - accuracy: 0.1744\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8381e-04 - accuracy: 0.1744\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8109e-04 - accuracy: 0.1744\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8027e-04 - accuracy: 0.1744\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2298e-04 - accuracy: 0.1744\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5833e-04 - accuracy: 0.1744\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5697e-04 - accuracy: 0.1744\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8230e-04 - accuracy: 0.1744\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3317e-04 - accuracy: 0.1744\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8625e-04 - accuracy: 0.1744\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9736e-04 - accuracy: 0.1744\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2713e-04 - accuracy: 0.1744\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4824e-04 - accuracy: 0.1744\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9467e-04 - accuracy: 0.1743\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7956e-04 - accuracy: 0.1744\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8279e-04 - accuracy: 0.1744\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.6599e-04 - accuracy: 0.1744\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6212e-04 - accuracy: 0.1744\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9058e-04 - accuracy: 0.1744\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3817e-04 - accuracy: 0.1744\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9759e-04 - accuracy: 0.1744\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5335e-04 - accuracy: 0.1744\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6172e-04 - accuracy: 0.1744\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2018e-04 - accuracy: 0.1744\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.3990e-04 - accuracy: 0.1744\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4991e-04 - accuracy: 0.1744\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8343e-04 - accuracy: 0.1743\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4621e-04 - accuracy: 0.1744\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1248e-04 - accuracy: 0.1744\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.2879e-04 - accuracy: 0.1744\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9692e-04 - accuracy: 0.1744\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4075e-04 - accuracy: 0.1744\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0481e-04 - accuracy: 0.1744\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3037e-04 - accuracy: 0.1743\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0594e-04 - accuracy: 0.1744\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8404e-04 - accuracy: 0.1744\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4077e-04 - accuracy: 0.1744\n",
      "Epoch 227/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0479e-04 - accuracy: 0.1744\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4597e-04 - accuracy: 0.1744\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4711e-04 - accuracy: 0.1744\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.8718e-04 - accuracy: 0.1743\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2500e-04 - accuracy: 0.1744\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0518e-04 - accuracy: 0.1744\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4241e-04 - accuracy: 0.1744\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8021e-04 - accuracy: 0.1744\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4112e-04 - accuracy: 0.1744\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1655e-04 - accuracy: 0.1744\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7250e-04 - accuracy: 0.1744\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.4781e-04 - accuracy: 0.1744\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7685e-04 - accuracy: 0.1744\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5536e-04 - accuracy: 0.1744\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5293e-04 - accuracy: 0.1744\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8876e-04 - accuracy: 0.1744\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.4667e-04 - accuracy: 0.1744\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5196e-04 - accuracy: 0.1744\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6622e-04 - accuracy: 0.1744\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7377e-04 - accuracy: 0.1744\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4044e-04 - accuracy: 0.1744\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8700e-04 - accuracy: 0.1744\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9599e-04 - accuracy: 0.1744\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0981e-04 - accuracy: 0.1744\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4951e-04 - accuracy: 0.1744\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0032e-04 - accuracy: 0.1744\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0499e-04 - accuracy: 0.1744\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1097e-04 - accuracy: 0.1744\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0862e-04 - accuracy: 0.1744\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5047e-04 - accuracy: 0.1744\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3652e-04 - accuracy: 0.1744\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1577e-04 - accuracy: 0.1744\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9414e-04 - accuracy: 0.1744\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3576e-04 - accuracy: 0.1744\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7095e-04 - accuracy: 0.1744\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9307e-04 - accuracy: 0.1744\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5007e-04 - accuracy: 0.1744\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5954e-04 - accuracy: 0.1744\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5105e-04 - accuracy: 0.1744\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9852e-04 - accuracy: 0.1744\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3334e-04 - accuracy: 0.1744\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8329e-04 - accuracy: 0.1744\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0061e-04 - accuracy: 0.1744\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1910e-04 - accuracy: 0.1744\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1218e-04 - accuracy: 0.1744\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8758e-04 - accuracy: 0.1744\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5150e-04 - accuracy: 0.1744\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3022e-04 - accuracy: 0.1744\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9964e-04 - accuracy: 0.1744\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.4373e-04 - accuracy: 0.1744\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.2719e-04 - accuracy: 0.1744\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.8375e-04 - accuracy: 0.1743\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.3194e-04 - accuracy: 0.1744\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 7.3394e-04 - accuracy: 0.1743\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 8.0377e-04 - accuracy: 0.1744\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3019e-04 - accuracy: 0.1744\n",
      "Epoch 283/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7879e-04 - accuracy: 0.1744\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.1042e-04 - accuracy: 0.1744\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0195e-04 - accuracy: 0.1744\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4193e-04 - accuracy: 0.1744\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1869e-04 - accuracy: 0.1744\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0018e-04 - accuracy: 0.1744\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5073e-04 - accuracy: 0.1744\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5420e-04 - accuracy: 0.1744\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6064e-04 - accuracy: 0.1744\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5216e-04 - accuracy: 0.1744\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4099e-04 - accuracy: 0.1744\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3339e-04 - accuracy: 0.1744\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2540e-04 - accuracy: 0.1744\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1189e-04 - accuracy: 0.1744\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7905e-04 - accuracy: 0.1744\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6676e-04 - accuracy: 0.1744\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8658e-04 - accuracy: 0.1744\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6112e-04 - accuracy: 0.1744\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5790e-04 - accuracy: 0.1744\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3960e-04 - accuracy: 0.1744\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4555e-04 - accuracy: 0.1744\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8425e-04 - accuracy: 0.1744\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4253e-04 - accuracy: 0.1744\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4411e-04 - accuracy: 0.1744\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.1139e-04 - accuracy: 0.1744\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6513e-04 - accuracy: 0.1744\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2902e-04 - accuracy: 0.1744\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1729e-04 - accuracy: 0.1744\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2693e-04 - accuracy: 0.1744\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7393e-04 - accuracy: 0.1744\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1964e-04 - accuracy: 0.1744\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5046e-04 - accuracy: 0.1744\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1135e-04 - accuracy: 0.1744\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0542e-04 - accuracy: 0.1744\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3362e-04 - accuracy: 0.1744\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9073e-04 - accuracy: 0.1744\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0282e-04 - accuracy: 0.1744\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0806e-04 - accuracy: 0.1744\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8335e-04 - accuracy: 0.1744\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8089e-04 - accuracy: 0.1744\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1232e-04 - accuracy: 0.1744\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4482e-04 - accuracy: 0.1744\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2224e-04 - accuracy: 0.1744\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7326e-04 - accuracy: 0.1744\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5685e-04 - accuracy: 0.1744\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1863e-04 - accuracy: 0.1743\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0335e-04 - accuracy: 0.1744\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6790e-04 - accuracy: 0.1744\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2962e-04 - accuracy: 0.1744\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9766e-04 - accuracy: 0.1744\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1839e-04 - accuracy: 0.1744\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0837e-04 - accuracy: 0.1744\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6396e-04 - accuracy: 0.1744\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0103e-04 - accuracy: 0.1744\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2923e-04 - accuracy: 0.1744\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8318e-04 - accuracy: 0.1744\n",
      "Epoch 339/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5130e-04 - accuracy: 0.1744\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.0120e-04 - accuracy: 0.1744\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2510e-04 - accuracy: 0.1744\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6884e-04 - accuracy: 0.1744\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3337e-04 - accuracy: 0.1744\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6626e-04 - accuracy: 0.1744\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2694e-04 - accuracy: 0.1744\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7514e-04 - accuracy: 0.1744\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6694e-04 - accuracy: 0.1744\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4026e-04 - accuracy: 0.1744\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4349e-04 - accuracy: 0.1744\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3999e-04 - accuracy: 0.1744\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3276e-04 - accuracy: 0.1744\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7891e-04 - accuracy: 0.1744\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1509e-04 - accuracy: 0.1744\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9464e-04 - accuracy: 0.1744\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.5339e-04 - accuracy: 0.1744\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8110e-04 - accuracy: 0.1744\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4537e-04 - accuracy: 0.1744\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7968e-04 - accuracy: 0.1744\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6546e-04 - accuracy: 0.1744\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6961e-04 - accuracy: 0.1744\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2997e-04 - accuracy: 0.1744\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0846e-04 - accuracy: 0.1744\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3120e-04 - accuracy: 0.1744\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1221e-04 - accuracy: 0.1744\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.3058e-04 - accuracy: 0.1744\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8288e-04 - accuracy: 0.1744\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6346e-04 - accuracy: 0.1744\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7342e-04 - accuracy: 0.1744\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5154e-04 - accuracy: 0.1744\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2452e-04 - accuracy: 0.1744\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3284e-04 - accuracy: 0.1744\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1568e-04 - accuracy: 0.1744\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5305e-04 - accuracy: 0.1744\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6121e-04 - accuracy: 0.1744\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9166e-04 - accuracy: 0.1744\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0735e-04 - accuracy: 0.1744\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4287e-04 - accuracy: 0.1744\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9866e-04 - accuracy: 0.1744\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6297e-04 - accuracy: 0.1744\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4200e-04 - accuracy: 0.1744\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.8317e-04 - accuracy: 0.1744\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6444e-04 - accuracy: 0.1744\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5468e-04 - accuracy: 0.1744\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1108e-04 - accuracy: 0.1744\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2577e-04 - accuracy: 0.1744\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7412e-04 - accuracy: 0.1744\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1819e-04 - accuracy: 0.1744\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8036e-04 - accuracy: 0.1744\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3578e-04 - accuracy: 0.1744\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7339e-04 - accuracy: 0.1744\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9859e-04 - accuracy: 0.1744\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7054e-04 - accuracy: 0.1744\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4796e-04 - accuracy: 0.1744\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9848e-04 - accuracy: 0.1744\n",
      "Epoch 395/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3896e-04 - accuracy: 0.1744\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9449e-04 - accuracy: 0.1744\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0684e-04 - accuracy: 0.1744\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2438e-04 - accuracy: 0.1744\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0736e-04 - accuracy: 0.1744\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0885e-04 - accuracy: 0.1744\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7404e-04 - accuracy: 0.1744\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0479e-04 - accuracy: 0.1744\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8095e-04 - accuracy: 0.1744\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6277e-04 - accuracy: 0.1744\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8115e-04 - accuracy: 0.1744\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5587e-04 - accuracy: 0.1744\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0442e-04 - accuracy: 0.1744\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3260e-04 - accuracy: 0.1744\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1655e-04 - accuracy: 0.1744\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6765e-04 - accuracy: 0.1744\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0515e-04 - accuracy: 0.1744\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3958e-04 - accuracy: 0.1744\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4769e-04 - accuracy: 0.1744\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1555e-04 - accuracy: 0.1744\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2211e-04 - accuracy: 0.1744\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7146e-04 - accuracy: 0.1744\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6353e-04 - accuracy: 0.1744\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1645e-04 - accuracy: 0.1744\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7867e-04 - accuracy: 0.1744\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2626e-04 - accuracy: 0.1744\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6295e-04 - accuracy: 0.1744\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0145e-04 - accuracy: 0.1744\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0692e-04 - accuracy: 0.1744\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4111e-04 - accuracy: 0.1744\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4904e-04 - accuracy: 0.1744\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1952e-04 - accuracy: 0.1744\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 7.5639e-04 - accuracy: 0.1744\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3646e-04 - accuracy: 0.1744\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5409e-04 - accuracy: 0.1744\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6163e-04 - accuracy: 0.1744\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.1367e-04 - accuracy: 0.1744\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9232e-04 - accuracy: 0.1744\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.1011e-04 - accuracy: 0.1744\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4091e-04 - accuracy: 0.1744\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0848e-04 - accuracy: 0.1744\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.9977e-04 - accuracy: 0.1744\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9342e-04 - accuracy: 0.1744\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2794e-04 - accuracy: 0.1744\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.8713e-04 - accuracy: 0.1744\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.9819e-04 - accuracy: 0.1744\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.9600e-04 - accuracy: 0.1744\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.4841e-04 - accuracy: 0.1744\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.9912e-04 - accuracy: 0.1744\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.8130e-04 - accuracy: 0.1744\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.4301e-04 - accuracy: 0.1744\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.3014e-04 - accuracy: 0.1744\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.2948e-04 - accuracy: 0.1744\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3727e-04 - accuracy: 0.1744\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.4193e-04 - accuracy: 0.1744\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3701e-04 - accuracy: 0.1744\n",
      "Epoch 451/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.7051e-04 - accuracy: 0.1744\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4875e-04 - accuracy: 0.1744\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9698e-04 - accuracy: 0.1744\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.2649e-04 - accuracy: 0.1744\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8253e-04 - accuracy: 0.1744\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8704e-04 - accuracy: 0.1744\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.5647e-04 - accuracy: 0.1744\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.1124e-04 - accuracy: 0.1744\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7210e-04 - accuracy: 0.1744\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9318e-04 - accuracy: 0.1744\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4321e-04 - accuracy: 0.1744\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 5.9383e-04 - accuracy: 0.1744\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5431e-04 - accuracy: 0.1744\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3719e-04 - accuracy: 0.1744\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6746e-04 - accuracy: 0.1744\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.5559e-04 - accuracy: 0.1744\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0496e-04 - accuracy: 0.1744\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8152e-04 - accuracy: 0.1744\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3402e-04 - accuracy: 0.1744\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9935e-04 - accuracy: 0.1744\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0840e-04 - accuracy: 0.1744\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0686e-04 - accuracy: 0.1744\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.4083e-04 - accuracy: 0.1744\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8553e-04 - accuracy: 0.1744\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7147e-04 - accuracy: 0.1744\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9567e-04 - accuracy: 0.1744\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.9974e-04 - accuracy: 0.1744\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8194e-04 - accuracy: 0.1744\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7394e-04 - accuracy: 0.1744\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6001e-04 - accuracy: 0.1744\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3314e-04 - accuracy: 0.1744\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6381e-04 - accuracy: 0.1744\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9770e-04 - accuracy: 0.1744\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.2549e-04 - accuracy: 0.1744\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.8110e-04 - accuracy: 0.1744\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6984e-04 - accuracy: 0.1744\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.4752e-04 - accuracy: 0.1744\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.6962e-04 - accuracy: 0.1744\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.4424e-04 - accuracy: 0.1744\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7384e-04 - accuracy: 0.1744\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9448e-04 - accuracy: 0.1744\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.4451e-04 - accuracy: 0.1744\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 6.1224e-04 - accuracy: 0.1744\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0674e-04 - accuracy: 0.1744\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.5264e-04 - accuracy: 0.1744\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.9353e-04 - accuracy: 0.1744\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.7464e-04 - accuracy: 0.1744\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.0060e-04 - accuracy: 0.1744\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 5.6024e-04 - accuracy: 0.1744\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 6.3017e-04 - accuracy: 0.1744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa842c7df10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ : ì˜¤ëŠ˜ ë­ ë¨¹ì„ê¹Œìš”?\n",
      "ì¶œë ¥ : ë§›ìˆëŠ” ê±° ë“œì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ìì‚´í•˜ê³  ì‹¶ì–´\n",
      "ì¶œë ¥ : ê°€ë‘ë¹„ì— ì˜· ì –ëŠ” ë“¯í•œ ì‚¬ë‘ì´ì—ˆë‚˜ë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?\n",
      "ì¶œë ¥ : ê°„ì ˆíˆ ì›í•œë‹¤ë©´ ì§„ì‹¬ì„ ì „í•´ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„Œ ëˆ„êµ¬ì•¼?\n",
      "ì¶œë ¥ : ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤ .\n",
      "\n",
      "ì…ë ¥ : ì¸ìƒì€ ë­˜ê¹Œ\n",
      "ì¶œë ¥ : ì‚¬ë‘ì€ ì•Œ ìˆ˜ ì—†ì–´ìš” . ë‹¨ì§€ ëŠê»´ì§ˆ ë¿ .\n",
      "\n",
      "ì…ë ¥ : ë„ˆ ë­ ì¢‹ì•„í•´?\n",
      "ì¶œë ¥ : ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .\n",
      "\n",
      "ì…ë ¥ : ê³µë¶€ ì¢€ ëŒ€ì‹ í•´ì¤˜\n",
      "ì¶œë ¥ : ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì‚¬ë‘í•´\n",
      "ì¶œë ¥ : í•˜ëŠ˜ ë§Œí¼ ë•… ë§Œí¼ ì‚¬ë‘í•´ìš” .\n",
      "\n",
      "ì…ë ¥ : í”¼ê³¤í•´\n",
      "ì¶œë ¥ : ìš”ì¦˜ ë°”ìœê°€ë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ê·¸ë™ì•ˆ ì¦ê±°ì› ì–´\n",
      "ì¶œë ¥ : í•  ì¼ì´ ë§ì€ë° ì•ˆí•˜ëŠ” ê²ƒì´ìš” .\n",
      "\n",
      "ì…ë ¥ : ìë‹ˆ?\n",
      "ì¶œë ¥ : ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : í˜ë“¤ì–´\n",
      "ì¶œë ¥ : ì§€ê¸ˆì€ í˜ë“¤ê² ì§€ë§Œ ì¡°ê¸ˆë§Œ ë” ê²¬ëŒë´ìš” .\n",
      "\n",
      "ì…ë ¥ : ë†€ì•„ì¤˜\n",
      "ì¶œë ¥ : ì§€ê¸ˆ ê·¸ëŸ¬ê³  ìˆì–´ìš” .\n",
      "\n",
      "ì…ë ¥ : ì¢…êµê°€ ë­ì•¼?\n",
      "ì¶œë ¥ : ì¢…êµê°€ í° ë¬¸ì œê°€ ë˜ê¸°ë„ í•˜ì£  .\n",
      "\n",
      "ì…ë ¥ : ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜\n",
      "ì¶œë ¥ : ëƒ‰ì¥ê³  íŒŒë¨¹ê¸° í•´ë³´ì„¸ìš” .\n",
      "\n",
      "ì…ë ¥ : ì˜¤ëœë§Œì´ì•¼\n",
      "ì¶œë ¥ : ì˜¤ëœë§Œì´ì—ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” ì–´ë–»ê²Œ ê¸°ë¶„ì „í™˜í•´?\n",
      "ì¶œë ¥ : ì•ˆ ê´œì°®ì•„ë„ ë¼ìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆì˜ ê¿ˆì´ ë­ì•¼?\n",
      "ì¶œë ¥ : ë” ì¢‹ì€ ì‚¬ëŒ ë§Œë‚˜ì„œ ì•Œì½©ë‹¬ì½© ì—°ì• í•˜ê³  í–‰ë³µí•œ ê²°í˜¼ìƒí™œ í•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš” .\n",
      "\n",
      "ì…ë ¥ : ë„ˆëŠ” í–‰ë³µí•´?\n",
      "ì¶œë ¥ : ì €ëŠ” ë°°í„°ë¦¬ê°€ ë°¥ì´ì˜ˆìš” .\n",
      "\n",
      "ì…ë ¥ : ì›ƒì–´ì¤˜\n",
      "ì¶œë ¥ : ê¸°ëŒ€ë¥¼ ë§ì´ í•˜ëŠ” ê±´ ì¢‹ì§€ ì•Šì•„ìš” .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers(question_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê²°ê³¼ ì •ë¦¬"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|QUESTION|ì—í­ 10 - loss: 0.5058, acc: 0.0940|ì—í­ 300 - loss: 8.0652e-04, acc: 0.1743|ì—í­ 500 - loss: 6.3017e-04, acc: 0.1744|\n",
    "|:---|:---:|:---:|:---:|\n",
    "|**ì…ë ¥ : ì˜¤ëŠ˜ ë­ ë¨¹ì„ê¹Œìš”?**|ì˜ ì°¾ì•„ë³´ì„¸ìš” .|ì¢€ ë¨¹ì–´ë„ ê´œì°®ì•„ìš” .|ë§›ìˆëŠ” ê±° ë“œì„¸ìš” .|\n",
    "|**ì…ë ¥ : ìì‚´í•˜ê³  ì‹¶ì–´**|ì˜ ì°¾ì•„ë³´ì„¸ìš” .|ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .|ê°€ë‘ë¹„ì— ì˜· ì –ëŠ” ë“¯í•œ ì‚¬ë‘ì´ì—ˆë‚˜ë´ìš” .|\n",
    "|**ì…ë ¥ : ì˜¤ëŠ˜ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œìš”?**|ê·¸ê²Œ ìµœê³ ì£  .|ë”± ì˜ ë§Œë‚¬ë„¤ìš” .|ê°„ì ˆíˆ ì›í•œë‹¤ë©´ ì§„ì‹¬ì„ ì „í•´ë³´ì„¸ìš” .|\n",
    "|**ì…ë ¥ : ë„Œ ëˆ„êµ¬ì•¼?**|ë‹¤ë¥¸ ê³³ì— ì“°ë ¤ê³  ìš´ì„ ì•„ê»´ë’€ë‚˜ë´ìš” .|ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤ .|ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤ .|\n",
    "|**ì…ë ¥ : ì¸ìƒì€ ë­˜ê¹Œ**|ì €ë„ ì¢‹ì•„í•´ìš” .|ê½ƒê¸¸ë§Œ ê±·ê¸¸ ë°”ëë‹ˆë‹¤ .|ì‚¬ë‘ì€ ì•Œ ìˆ˜ ì—†ì–´ìš” . ë‹¨ì§€ ëŠê»´ì§ˆ ë¿ .|\n",
    "|**ì…ë ¥ : ë„ˆ ë­ ì¢‹ì•„í•´?**|ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .|ê³ ë°±í•˜ì„¸ìš” .|ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .|\n",
    "|**ì…ë ¥ : ê³µë¶€ ì¢€ ëŒ€ì‹ í•´ì¤˜**|ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .|ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .|ì§€ê¸ˆë„ ëŠ¦ì§€ ì•Šì•˜ì–´ìš” .|\n",
    "|**ì…ë ¥ : ì‚¬ë‘í•´**|ì¡°ê¸ˆë§Œ ë“œì„¸ìš” .|í•˜ëŠ˜ ë§Œí¼ ë•… ë§Œí¼ ì‚¬ë‘í•´ìš” .|í•˜ëŠ˜ ë§Œí¼ ë•… ë§Œí¼ ì‚¬ë‘í•´ìš” .|\n",
    "|**ì…ë ¥ : í”¼ê³¤í•´**|ê³§ ë°©í•™ì´ì˜ˆìš” .|ìš”ì¦˜ ë°”ìœê°€ë´ìš” .|ìš”ì¦˜ ë°”ìœê°€ë´ìš” .|\n",
    "|**ì…ë ¥ : ê·¸ë™ì•ˆ ì¦ê±°ì› ì–´**|ê°ê¸° ì¡°ì‹¬í•˜ì„¸ìš” .|í•  ì¼ì´ ë§ì€ë° ì•ˆí•˜ëŠ” ê²ƒì´ìš” .|í•  ì¼ì´ ë§ì€ë° ì•ˆí•˜ëŠ” ê²ƒì´ìš” .|\n",
    "|**ì…ë ¥ : ìë‹ˆ?**|ë§›ìˆê²Œ ë“œì„¸ìš” .|ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .|ê¸°ë‹¤ë¦¬ê³  ìˆì—ˆì–´ìš” .|\n",
    "|**ì…ë ¥ : í˜ë“¤ì–´**|ì¡°ê¸ˆë§Œ ë” ë²„í…¨ë³´ì„¸ìš” .|ì§€ê¸ˆì€ í˜ë“¤ê² ì§€ë§Œ ì¡°ê¸ˆë§Œ ë” ê²¬ëŒë´ìš” .|ì§€ê¸ˆì€ í˜ë“¤ê² ì§€ë§Œ ì¡°ê¸ˆë§Œ ë” ê²¬ëŒë´ìš” .|\n",
    "|**ì…ë ¥ : ë†€ì•„ì¤˜**|ê°™ì´ ë†€ì•„ìš” .|ì§€ê¸ˆ ê·¸ëŸ¬ê³  ìˆì–´ìš” .|ì§€ê¸ˆ ê·¸ëŸ¬ê³  ìˆì–´ìš” .|\n",
    "|**ì…ë ¥ : ì¢…êµê°€ ë­ì•¼?**|í™”ì¥ì‹¤ ê°€ì„¸ìš” .|ì¢…êµê°€ í° ë¬¸ì œê°€ ë˜ê¸°ë„ í•˜ì£  .|ì¢…êµê°€ í° ë¬¸ì œê°€ ë˜ê¸°ë„ í•˜ì£  .|\n",
    "|**ì…ë ¥ : ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì¤˜**|ë§›ìˆëŠ” ê±° ë“œì„¸ìš” .|ëƒ‰ì¥ê³  íŒŒë¨¹ê¸° í•´ë³´ì„¸ìš” .|ëƒ‰ì¥ê³  íŒŒë¨¹ê¸° í•´ë³´ì„¸ìš” .|\n",
    "|**ì…ë ¥ : ì˜¤ëœë§Œì´ì•¼**|ë” ì¢‹ì€ ì‚¬ëŒ ë§Œë‚  ìˆ˜ ìˆì„ ê±°ì˜ˆìš” .|ì˜¤ëœë§Œì´ì—ìš” .|ì˜¤ëœë§Œì´ì—ìš” .|\n",
    "|**ì…ë ¥ : ë„ˆëŠ” ì–´ë–»ê²Œ ê¸°ë¶„ì „í™˜í•´?**|ë‹¤ë¥¸ ê³³ì— ì“°ë ¤ê³  ìš´ì„ ì•„ê»´ë’€ë‚˜ë´ìš” .|ì•„ì§ ì•ˆ ììš” .|ì•ˆ ê´œì°®ì•„ë„ ë¼ìš” .|\n",
    "|**ì…ë ¥ : ë„ˆì˜ ê¿ˆì´ ë­ì•¼?**|ì €ëŠ” ìœ„ë¡œí•´ë“œë¦¬ëŠ” ë¡œë´‡ì´ì—ìš” .|ì²œì²œíˆ ì§€ì›Œì§ˆ ê±°ì˜ˆìš” .|ë” ì¢‹ì€ ì‚¬ëŒ ë§Œë‚˜ì„œ ì•Œì½©ë‹¬ì½© ì—°ì• í•˜ê³  í–‰ë³µí•œ ê²°í˜¼ìƒí™œ í•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš” .|\n",
    "|**ì…ë ¥ : ë„ˆëŠ” í–‰ë³µí•´?**|ì˜ ì°¾ì•„ë³´ì„¸ìš” .|ì €ëŠ” ë‘˜ì´ ê°€ëŠ” ê²Œ ì¢‹ì•„ìš” .|ì €ëŠ” ë°°í„°ë¦¬ê°€ ë°¥ì´ì˜ˆìš” .|\n",
    "|**ì…ë ¥ : ì›ƒì–´ì¤˜**|ì˜¤ëŠ˜ ì¼ì° ì£¼ë¬´ì„¸ìš” .|ê¸°ëŒ€ë¥¼ ì¡°ê¸ˆì”© ë²„ë ¤ë³´ì„¸ìš” .|ê¸°ëŒ€ë¥¼ ë§ì´ í•˜ëŠ” ê±´ ì¢‹ì§€ ì•Šì•„ìš” .|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# íšŒê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- íŠ¸ëœìŠ¤í¬ë¨¸ì— ëŒ€í•´ì„œ ë°°ìš°ë©´ì„œ ëª¨ë¥´ëŠ” ë¶€ë¶„ì´ ë„ˆë¬´ ë§ì•˜ê³  ì´ë²ˆ ë…¸ë“œë¥¼ ì§„í–‰í•˜ë©´ì„œ ìƒˆë¡œìš´ ë¶€ë¶„ì„ ë°°ì› ì§€ë§Œ, ë„ˆë¬´ ì–´ë ¤ì›Œ ë‹¤ì‹œ ì´í•´í•˜ëŠ”ë° ì˜¤ë˜ê±¸ë¦´ê²ƒê°™ë‹¤.\n",
    "- ê·¸ë¦¬ê³  LMS ë…¸ë“œ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë“¤ê³ ì™€ì„œ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤ë³´ë‹ˆ ì½”ë“œ ì´í•´ë¥¼ ë” ë…¸ë ¥í•´ì•¼í•  ê²ƒ ê°™ë‹¤.\n",
    "- ì‹¤í—˜ ê²°ê³¼ë¡œ ì—í­ 10, 300, 500ì—ì„œ ê²°ê³¼ë¥¼ ë³´ì•˜ê³ , epoch ê°’ì´ í´ìˆ˜ë¡ Loss ê°’ì€ ë‚®ì•„ì¡Œë‹¤.\n",
    "- í•˜ì§€ë§Œ epoch ê°’ì´ ì¼ì • ìˆ˜ì¤€ì´ ì§€ë‚˜ë©´ accuracyëŠ” ë” ì´ìƒ ìƒìŠ¹í•˜ì§€ ì•Šê³  1.744ì—ì„œ ë©ˆì¶°ìˆë‹¤.\n",
    "- epoch ê°’ì´ ë†’ì€ ê²ƒì´ ê·¸ë‚˜ë§ˆ ì…ë ¥ì— ëŒ€í•œ ì¶œë ¥ì„ ì ì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” ê²ƒ ê°™ë‹¤.\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ë” ì¡°ì ˆí•´ì„œ ì—¬ëŸ¬ ì‹¤í—˜ì„ í•´ë³´ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¬ ìˆ˜ë„ ìˆê² ì§€ë§Œ, ì‹œê°„ì´ ë¶€ì¡±í•˜ì—¬ ì‹¤í—˜í•˜ì§€ ëª»í•˜ì˜€ë‹¤."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
